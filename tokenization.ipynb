{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2ce03eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8de5e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package nltk:\n",
      "\n",
      "NAME\n",
      "    nltk\n",
      "\n",
      "DESCRIPTION\n",
      "    The Natural Language Toolkit (NLTK) is an open source Python library\n",
      "    for Natural Language Processing.  A free online book is available.\n",
      "    (If you use the library for academic research, please cite the book.)\n",
      "    \n",
      "    Steven Bird, Ewan Klein, and Edward Loper (2009).\n",
      "    Natural Language Processing with Python.  O'Reilly Media Inc.\n",
      "    https://www.nltk.org/book/\n",
      "    \n",
      "    isort:skip_file\n",
      "    \n",
      "    @version: 3.9.1\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    app (package)\n",
      "    book\n",
      "    ccg (package)\n",
      "    chat (package)\n",
      "    chunk (package)\n",
      "    classify (package)\n",
      "    cli\n",
      "    cluster (package)\n",
      "    collections\n",
      "    collocations\n",
      "    compat\n",
      "    corpus (package)\n",
      "    data\n",
      "    decorators\n",
      "    downloader\n",
      "    draw (package)\n",
      "    featstruct\n",
      "    grammar\n",
      "    help\n",
      "    inference (package)\n",
      "    internals\n",
      "    jsontags\n",
      "    langnames\n",
      "    lazyimport\n",
      "    lm (package)\n",
      "    metrics (package)\n",
      "    misc (package)\n",
      "    parse (package)\n",
      "    probability\n",
      "    sem (package)\n",
      "    sentiment (package)\n",
      "    stem (package)\n",
      "    tabdata\n",
      "    tag (package)\n",
      "    tbl (package)\n",
      "    test (package)\n",
      "    text\n",
      "    tgrep\n",
      "    tokenize (package)\n",
      "    toolbox\n",
      "    translate (package)\n",
      "    tree (package)\n",
      "    treeprettyprinter\n",
      "    treetransforms\n",
      "    twitter (package)\n",
      "    util\n",
      "    wsd\n",
      "\n",
      "SUBMODULES\n",
      "    agreement\n",
      "    aline\n",
      "    api\n",
      "    arlstem\n",
      "    arlstem2\n",
      "    association\n",
      "    bleu_score\n",
      "    bllip\n",
      "    boxer\n",
      "    brill\n",
      "    brill_trainer\n",
      "    casual\n",
      "    chart\n",
      "    chrf_score\n",
      "    cistem\n",
      "    confusionmatrix\n",
      "    corenlp\n",
      "    crf\n",
      "    decisiontree\n",
      "    dependencygraph\n",
      "    destructive\n",
      "    discourse\n",
      "    distance\n",
      "    drt\n",
      "    earleychart\n",
      "    evaluate\n",
      "    featurechart\n",
      "    gale_church\n",
      "    gdfa\n",
      "    gleu_score\n",
      "    glue\n",
      "    hmm\n",
      "    hunpos\n",
      "    ibm1\n",
      "    ibm2\n",
      "    ibm3\n",
      "    ibm4\n",
      "    ibm5\n",
      "    ibm_model\n",
      "    isri\n",
      "    lancaster\n",
      "    legality_principle\n",
      "    lfg\n",
      "    linearlogic\n",
      "    logic\n",
      "    mace\n",
      "    malt\n",
      "    mapping\n",
      "    maxent\n",
      "    megam\n",
      "    meteor_score\n",
      "    mwe\n",
      "    naivebayes\n",
      "    named_entity\n",
      "    nist_score\n",
      "    nonprojectivedependencyparser\n",
      "    paice\n",
      "    pchart\n",
      "    perceptron\n",
      "    phrase_based\n",
      "    porter\n",
      "    positivenaivebayes\n",
      "    projectivedependencyparser\n",
      "    prover9\n",
      "    punkt\n",
      "    recursivedescent\n",
      "    regexp\n",
      "    relextract\n",
      "    repp\n",
      "    resolution\n",
      "    ribes_score\n",
      "    rslp\n",
      "    rte_classify\n",
      "    scikitlearn\n",
      "    scores\n",
      "    segmentation\n",
      "    senna\n",
      "    sequential\n",
      "    sexpr\n",
      "    shiftreduce\n",
      "    simple\n",
      "    snowball\n",
      "    sonority_sequencing\n",
      "    spearman\n",
      "    stack_decoder\n",
      "    stanford\n",
      "    stanford_segmenter\n",
      "    tableau\n",
      "    tadm\n",
      "    textcat\n",
      "    texttiling\n",
      "    tnt\n",
      "    toktok\n",
      "    transitionparser\n",
      "    treebank\n",
      "    viterbi\n",
      "    weka\n",
      "    wordnet\n",
      "\n",
      "FUNCTIONS\n",
      "    demo()\n",
      "        # FIXME:  override any accidentally imported demo, see https://github.com/nltk/nltk/issues/2116\n",
      "    \n",
      "    tee(iterable, n=2, /)\n",
      "        Returns a tuple of n independent iterators.\n",
      "\n",
      "DATA\n",
      "    PRETRAINED_TAGGERS = {'eng': 'taggers/averaged_perceptron_tagger_eng/'...\n",
      "    SLASH = *slash*\n",
      "    TYPE = *type*\n",
      "    __author_email__ = 'nltk.team@gmail.com'\n",
      "    __classifiers__ = ['Development Status :: 5 - Production/Stable', 'Int...\n",
      "    __copyright__ = 'Copyright (C) 2001-2024 NLTK Project.\\n\\nDistribut......\n",
      "    __keywords__ = ['NLP', 'CL', 'natural language processing', 'computati...\n",
      "    __license__ = 'Apache License, Version 2.0'\n",
      "    __longdescr__ = 'The Natural Language Toolkit (NLTK) is a Python ...LT...\n",
      "    __maintainer__ = 'NLTK Team'\n",
      "    __maintainer_email__ = 'nltk.team@gmail.com'\n",
      "    __url__ = 'https://www.nltk.org/'\n",
      "    app = <LazyModule 'nltk.app'>\n",
      "    chat = <LazyModule 'nltk.chat'>\n",
      "    corpus = <LazyModule 'nltk.corpus'>\n",
      "    infile = <_io.TextIOWrapper name='d:\\\\Natural Language Pr...ckages\\\\nl...\n",
      "    json_tags = {'!nltk.tag.BrillTagger': <class 'nltk.tag.brill.BrillTagg...\n",
      "    toolbox = <LazyModule 'nltk.toolbox'>\n",
      "    version_file = r'd:\\Natural Language Processing\\nlp\\Lib\\site-packages\\...\n",
      "\n",
      "VERSION\n",
      "    3.9.1\n",
      "\n",
      "AUTHOR\n",
      "    NLTK Team\n",
      "\n",
      "FILE\n",
      "    d:\\natural language processing\\nlp\\lib\\site-packages\\nltk\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69c08c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\"\n",
    "Hello! Welcome, To NLP Practice.\n",
    "Complete it with dedication, Consistency and with Discipline!.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470168a6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ac07c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hello! Welcome, To NLP Practice.\n",
      "Complete it with dedication, Consistency and with Discipline!.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69c7fb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to D:/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Force re-download in a known directory\n",
    "nltk.download('punkt_tab', download_dir='D:/nltk_data')\n",
    "\n",
    "# Tell NLTK to look there\n",
    "nltk.data.path.append('D:/nltk_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dea2ad7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hello! Welcome, To NLP Practice.\n",
      "Complete it with dedication, Consistency and with Discipline!.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "corpus = \"\"\"\n",
    "Hello! Welcome, To NLP Practice.\n",
    "Complete it with dedication, Consistency and with Discipline!.\n",
    "\"\"\"\n",
    "\n",
    "documents =(corpus)\n",
    "type(documents)\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "555fc283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Tokenization\n",
    "## Paragraph --> words\n",
    "## Sentence --> words\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "vocab = word_tokenize(corpus)\n",
    "type(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "42ae869d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "!\n",
      "Welcome\n",
      ",\n",
      "To\n",
      "NLP\n",
      "Practice\n",
      ".\n",
      "Complete\n",
      "it\n",
      "with\n",
      "dedication\n",
      ",\n",
      "Consistency\n",
      "and\n",
      "with\n",
      "Discipline\n",
      "!\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for word in vocab:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "deaaf681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5287f2b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " '!',\n",
       " 'Welcome',\n",
       " ',',\n",
       " 'To',\n",
       " 'NLP',\n",
       " 'Practice',\n",
       " '.',\n",
       " 'Complete',\n",
       " 'it',\n",
       " 'with',\n",
       " 'dedication',\n",
       " ',',\n",
       " 'Consistency',\n",
       " 'and',\n",
       " 'with',\n",
       " 'Discipline',\n",
       " '!.']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordpunct_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f4e761fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "267d2ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "de45cd4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " '!',\n",
       " 'Welcome',\n",
       " ',',\n",
       " 'To',\n",
       " 'NLP',\n",
       " 'Practice.',\n",
       " 'Complete',\n",
       " 'it',\n",
       " 'with',\n",
       " 'dedication',\n",
       " ',',\n",
       " 'Consistency',\n",
       " 'and',\n",
       " 'with',\n",
       " 'Discipline',\n",
       " '!',\n",
       " '.']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3738d51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
